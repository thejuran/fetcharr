---
phase: 06-bug-fixes-and-resilience
plan: 03
type: execute
wave: 2
depends_on:
  - 06-01
  - 06-02
files_modified:
  - fetcharr/logging.py
  - fetcharr/search/scheduler.py
  - fetcharr/web/routes.py
  - tests/test_logging.py
autonomous: true
requirements:
  - QUAL-01
  - QUAL-02
  - QUAL-05

must_haves:
  truths:
    - "Concurrent search cycles (scheduler + manual search-now) are serialized via asyncio.Lock -- no state corruption possible"
    - "Settings are validated via Pydantic model BEFORE writing to disk -- invalid config never reaches the TOML file"
    - "Log redaction covers exception tracebacks, not just log messages"
    - "After saving settings that change API keys, the redaction filter refreshes with the new secrets"
  artifacts:
    - path: "fetcharr/logging.py"
      provides: "create_redacting_sink function, updated setup_logging using custom sink"
      contains: "create_redacting_sink"
    - path: "fetcharr/search/scheduler.py"
      provides: "asyncio.Lock on app.state.search_lock, lock acquisition in make_search_job"
      contains: "search_lock"
    - path: "fetcharr/web/routes.py"
      provides: "Lock acquisition in search_now, validate-before-write in save_settings, redaction refresh"
      contains: "search_lock"
    - path: "tests/test_logging.py"
      provides: "Test for traceback redaction via custom sink"
      contains: "test_redaction_covers_tracebacks"
  key_links:
    - from: "fetcharr/search/scheduler.py"
      to: "app.state.search_lock"
      via: "asyncio.Lock created in lifespan, acquired in job closure"
      pattern: "search_lock"
    - from: "fetcharr/web/routes.py"
      to: "app.state.search_lock"
      via: "async with in search_now"
      pattern: "async with.*search_lock"
    - from: "fetcharr/web/routes.py"
      to: "Settings(**new_config)"
      via: "validate before write"
      pattern: "Settings\\(\\*\\*"
    - from: "fetcharr/logging.py"
      to: "create_redacting_sink"
      via: "sink function receives full formatted output including tracebacks"
      pattern: "create_redacting_sink"
---

<objective>
Add concurrency lock for search cycles, validate settings before writing to disk, and switch log redaction to custom sink for traceback coverage.

Purpose: Eliminate the race condition between scheduler and manual search (QUAL-01), prevent invalid config from reaching disk (QUAL-02), and ensure API keys in exception tracebacks are redacted (QUAL-05). These three fixes all touch the web routes and tie together the concurrency/validation/redaction concerns.

Output: Updated `fetcharr/logging.py`, `fetcharr/search/scheduler.py`, `fetcharr/web/routes.py`, and `tests/test_logging.py`.
</objective>

<execution_context>
@/Users/julianamacbook/.claude/get-shit-done/workflows/execute-plan.md
@/Users/julianamacbook/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-bug-fixes-and-resilience/06-RESEARCH.md
@.planning/phases/06-bug-fixes-and-resilience/06-01-SUMMARY.md
@.planning/phases/06-bug-fixes-and-resilience/06-02-SUMMARY.md
@fetcharr/logging.py
@fetcharr/search/scheduler.py
@fetcharr/web/routes.py
@fetcharr/startup.py
@tests/test_logging.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Replace filter-based log redaction with custom sink for traceback coverage</name>
  <files>fetcharr/logging.py, tests/test_logging.py</files>
  <action>
**In `fetcharr/logging.py`:**

Replace the entire module with the custom sink approach. Keep the module docstring but update it.

1. Replace `create_redaction_filter` with `create_redacting_sink`:
```python
def create_redacting_sink(secrets: list[str], stream=sys.stderr) -> Callable:
    """Create a loguru sink that redacts secrets from the full formatted output.

    Unlike a filter (which only sees record["message"]), a custom sink
    receives the COMPLETE formatted string including exception tracebacks.
    This ensures API keys that appear in httpx exception messages or
    stack traces are also redacted.

    Args:
        secrets: List of secret values to redact.
        stream: Output stream (defaults to stderr).

    Returns:
        A loguru-compatible sink function.
    """
    def sink(message):
        text = str(message)
        for secret in secrets:
            if secret:
                text = text.replace(secret, "[REDACTED]")
        stream.write(text)
        stream.flush()
    return sink
```

2. Update `setup_logging` to use the sink instead of filter:
```python
def setup_logging(level: str, secrets: list[str]) -> None:
    logger.remove()
    logger.add(
        create_redacting_sink(secrets),
        format="{time:YYYY-MM-DD HH:mm:ss} {level:<8} {message}",
        level=level.upper(),
        colorize=False,  # Custom sink function, not a stream -- no ANSI auto-detect
    )
```

Key detail: `colorize=False` because the sink is a function, not a file stream. Loguru can't auto-detect terminal support on a function. This is intentional -- the sink writes to stderr manually where ANSI codes are not guaranteed to be supported (e.g., container logs).

Keep the `create_redaction_filter` function available for backward compatibility BUT mark it as deprecated with a comment. Actually, no -- check if any tests import it. The existing tests in `test_logging.py` import `create_redaction_filter`. Update the tests to use the new function name instead. Remove `create_redaction_filter` entirely -- clean break.

**In `tests/test_logging.py`:**

1. Update the import: replace `create_redaction_filter` with `create_redacting_sink`.

2. Update `test_redaction_filter_removes_secret` to use the sink approach:
   - Create a `StringIO` output stream
   - Create a sink via `create_redacting_sink([secret], stream=output)`
   - Add the sink to loguru: `logger.add(sink, format="{message}", colorize=False)`
   - Log a message containing the secret
   - Assert secret is NOT in output, `[REDACTED]` IS in output

3. Update `test_redaction_filter_ignores_empty_secrets` similarly.

4. Add a NEW test `test_redaction_covers_tracebacks`:
   - Create a `StringIO` output stream
   - Create a sink with a known secret string (e.g., "super-secret-api-key")
   - Add the sink to loguru
   - Use `logger.opt(exception=True)` or create a try/except block that catches an exception whose message contains the secret, then log it with `logger.exception()`
   - Example: `try: raise ValueError("Connection failed with key super-secret-api-key"); except: logger.exception("API call failed")`
   - Assert the secret does NOT appear in output but `[REDACTED]` DOES
   - This proves the sink redacts tracebacks, not just messages

5. Update `test_log_format_matches_spec` -- it calls `setup_logging("info", [])` and then replaces handlers. Since `setup_logging` now uses `colorize=False`, the test should still work. Verify it doesn't break.
  </action>
  <verify>
    <automated>cd /Users/julianamacbook/fetcharr && python -m pytest tests/test_logging.py -x -q</automated>
    <manual>Verify all logging tests pass including the new traceback redaction test</manual>
  </verify>
  <done>logging.py uses create_redacting_sink (custom sink, not filter). Tracebacks are redacted. Tests updated and new traceback test added. All logging tests pass.</done>
</task>

<task type="auto">
  <name>Task 2: Add asyncio.Lock in scheduler and wire it into make_search_job</name>
  <files>fetcharr/search/scheduler.py</files>
  <action>
Two changes to `fetcharr/search/scheduler.py`:

**1. Create the lock in `create_lifespan` > `lifespan`:**
Add `import asyncio` at the top of the file. Inside the `lifespan` function, after the line `app.state.state_path = state_path`, add:
```python
app.state.search_lock = asyncio.Lock()
```

This creates a single lock shared by all search-related code paths via `app.state`.

**2. Acquire the lock in `make_search_job` > `job` closure:**
Wrap the entire job body (everything after `client = getattr(...)`) in `async with app.state.search_lock:`. The lock scope MUST include both the cycle call AND the `save_state` call -- saving outside the lock would still race. The `client is None` early return should remain OUTSIDE the lock (no need to acquire the lock just to check if client is None).

Updated `job` function:
```python
async def job() -> None:
    client = getattr(app.state, f"{app_name}_client", None)
    if client is None:
        return
    async with app.state.search_lock:
        try:
            app.state.fetcharr_state = await cycle_fn(
                client,
                app.state.fetcharr_state,
                app.state.settings,
            )
            save_state(app.state.fetcharr_state, state_path)
        except Exception as exc:
            logger.error(
                "{app}: Unhandled error in search cycle -- {exc}",
                app=app_name.title(),
                exc=exc,
            )
```

Key detail: `asyncio.Lock` is NOT reentrant, which is fine because neither the scheduler job nor the search-now handler calls the other. The lock prevents the scheduler from running a cycle while a manual search-now is in progress (and vice versa).
  </action>
  <verify>
    <automated>cd /Users/julianamacbook/fetcharr && python -m pytest tests/ -x -q</automated>
    <manual>Verify all tests pass (scheduler changes don't break existing web tests)</manual>
  </verify>
  <done>asyncio.Lock created in lifespan, acquired in make_search_job. Lock scope covers cycle + save_state. Client-is-None check remains outside lock.</done>
</task>

<task type="auto">
  <name>Task 3: Add lock in search_now, validate-before-write in save_settings, and redaction refresh</name>
  <files>fetcharr/web/routes.py</files>
  <action>
Three targeted changes to `fetcharr/web/routes.py`:

**1. Acquire the lock in `search_now` (QUAL-01):**
Wrap the cycle execution block in `async with request.app.state.search_lock:`. The lock scope must include both the `cycle_fn()` call and the `save_state()` call. The early returns (invalid app name, client is None) stay OUTSIDE the lock.

Replace lines 238-247 with:
```python
async with request.app.state.search_lock:
    try:
        request.app.state.fetcharr_state = await cycle_fn(
            client,
            request.app.state.fetcharr_state,
            request.app.state.settings,
        )
        save_state(
            request.app.state.fetcharr_state,
            request.app.state.state_path,
        )
        logger.info("{name}: Manual search triggered", name=app_name.title())
    except Exception as exc:
        logger.error(
            "{name}: Manual search failed -- {exc}",
            name=app_name.title(),
            exc=exc,
        )
```

**2. Validate settings before writing to disk (QUAL-02):**
In the `save_settings` function, add `from pydantic import ValidationError` at the top of the file (or use inline import). Before the existing `config_path.write_text(tomli_w.dumps(new_config))` line, add validation:

```python
# Validate BEFORE writing to disk (QUAL-02)
from fetcharr.models.config import Settings as SettingsModel
try:
    new_settings = SettingsModel(**new_config)
except Exception:
    logger.warning("Invalid settings rejected -- config file unchanged")
    return RedirectResponse(url="/settings", status_code=303)

# Config is valid -- write to disk
config_path.write_text(tomli_w.dumps(new_config))
os.chmod(config_path, 0o600)
request.app.state.settings = new_settings
```

Remove the old `new_settings = load_settings(config_path)` and `request.app.state.settings = new_settings` lines that came AFTER the file write. The `load_settings` import can stay (other code may use it) but is no longer used in `save_settings`.

Actually -- use the `Settings` import that's NOT already in the file. The `Settings` class is imported in `startup.py` but not in `routes.py`. Add `from fetcharr.models.config import Settings as SettingsModel` at the top-level imports. Use `SettingsModel` to avoid conflict if `Settings` is ever imported from another path. Catch `Exception` broadly (not just `ValidationError`) because `Settings(**new_config)` could also raise `TypeError` or other errors from malformed data.

**3. Refresh log redaction on settings save (QUAL-05):**
After `request.app.state.settings = new_settings` in `save_settings`, add:
```python
# Refresh log redaction with new secrets (QUAL-05)
from fetcharr.startup import collect_secrets
from fetcharr.logging import setup_logging as _setup_logging
secrets = collect_secrets(new_settings)
_setup_logging(new_settings.general.log_level, secrets)
```

Move these imports to the top-level imports section for cleanliness. The `setup_logging` function does `logger.remove()` + `logger.add()` internally, so calling it again is safe and replaces the old handler.

Note: use `_setup_logging` alias or just `setup_logging` -- there's no conflict since no other `setup_logging` is imported. Use the direct import at module level:
```python
from fetcharr.logging import setup_logging
from fetcharr.startup import collect_secrets
```

Be careful NOT to create a circular import. Check: `routes.py` -> `startup.py` -> `logging.py`. The `startup.py` imports from `fetcharr.logging` and `fetcharr.models.config`. The `routes.py` already imports from `fetcharr.config` and `fetcharr.search.*`. Adding `from fetcharr.startup import collect_secrets` and `from fetcharr.logging import setup_logging` should be safe (no circular dependency).
  </action>
  <verify>
    <automated>cd /Users/julianamacbook/fetcharr && python -m pytest tests/ -x -q</automated>
    <manual>Verify all tests pass including web route tests</manual>
  </verify>
  <done>search_now acquires the search_lock. save_settings validates via Settings(**new_config) BEFORE writing. Log redaction refreshes after settings save. All tests pass.</done>
</task>

</tasks>

<verification>
```bash
cd /Users/julianamacbook/fetcharr && python -m pytest tests/ -x -v
```
All tests pass. The three integration fixes (lock, validate-before-write, redaction refresh) work together correctly.
</verification>

<success_criteria>
- `logging.py` uses custom sink (not filter) -- tracebacks are redacted
- `scheduler.py` creates `asyncio.Lock` on `app.state.search_lock`
- `make_search_job` acquires the lock around cycle + save_state
- `search_now` acquires the same lock around cycle + save_state
- `save_settings` validates via `Settings(**new_config)` BEFORE writing TOML
- `save_settings` refreshes log redaction after settings change
- New traceback redaction test proves sink-based redaction works
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/06-bug-fixes-and-resilience/06-03-SUMMARY.md`
</output>
