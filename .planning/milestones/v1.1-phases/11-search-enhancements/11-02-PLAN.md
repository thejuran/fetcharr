---
phase: 11-search-enhancements
plan: 02
type: execute
wave: 2
depends_on:
  - "11-01"
files_modified:
  - pyproject.toml
  - fetcharr/db.py
  - fetcharr/search/engine.py
  - fetcharr/search/scheduler.py
  - fetcharr/web/routes.py
  - fetcharr/state.py
  - fetcharr/startup.py
  - fetcharr/templates/partials/search_log.html
  - tests/test_db.py
  - tests/test_search.py
  - tests/test_web.py
  - tests/conftest.py
autonomous: true
requirements:
  - SRCH-13

must_haves:
  truths:
    - "Search history entries are stored in a SQLite database at /config/fetcharr.db"
    - "Search history survives container restarts (data is on the /config volume)"
    - "The in-memory search_log list in state.json is replaced by SQLite storage"
    - "Existing search_log entries in state.json are migrated to SQLite on first boot"
    - "The dashboard still displays recent search history from SQLite (same UI, different backend)"
    - "Search log entries include timestamp, app name, queue type, and item name"
  artifacts:
    - path: "fetcharr/db.py"
      provides: "SQLite database module with init, insert, query, and migration functions"
      exports: ["init_db", "insert_search_entry", "get_recent_searches", "migrate_from_state"]
    - path: "pyproject.toml"
      provides: "aiosqlite dependency"
      contains: "aiosqlite"
    - path: "tests/test_db.py"
      provides: "Tests for SQLite module"
      contains: "test_"
  key_links:
    - from: "fetcharr/search/engine.py"
      to: "fetcharr/db.py"
      via: "insert_search_entry called instead of append_search_log"
      pattern: "insert_search_entry"
    - from: "fetcharr/web/routes.py"
      to: "fetcharr/db.py"
      via: "get_recent_searches for dashboard and search log partial"
      pattern: "get_recent_searches"
    - from: "fetcharr/search/scheduler.py"
      to: "fetcharr/db.py"
      via: "init_db called during lifespan startup, db_path on app.state"
      pattern: "init_db"
    - from: "fetcharr/db.py"
      to: "/config/fetcharr.db"
      via: "aiosqlite.connect for all database operations"
      pattern: "aiosqlite\\.connect"
---

<objective>
Replace the in-memory bounded search_log with a persistent SQLite database so search history survives container restarts and is queryable.

Purpose: Users lose all search history when the container restarts. SQLite provides durable, queryable storage on the existing /config volume with zero additional infrastructure.
Output: Working SQLite-backed search history with migration from existing state.json entries.
</objective>

<execution_context>
@/Users/julianamacbook/.claude/get-shit-done/workflows/execute-plan.md
@/Users/julianamacbook/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/11-search-enhancements/11-01-SUMMARY.md
@fetcharr/state.py
@fetcharr/search/engine.py
@fetcharr/search/scheduler.py
@fetcharr/web/routes.py
@fetcharr/templates/partials/search_log.html
@pyproject.toml
@tests/conftest.py
@tests/test_search.py
@tests/test_web.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create SQLite database module and add dependency</name>
  <files>
    pyproject.toml
    fetcharr/db.py
  </files>
  <action>
1. In `pyproject.toml`, add `"aiosqlite"` to the `dependencies` list. Then run `uv sync` to install it.

2. Create `fetcharr/db.py` with the following functions:

   **DB_PATH**: `Path("/config/fetcharr.db")` (same volume as config and state)

   **`async def init_db(db_path: Path = DB_PATH) -> None`**:
   - Connect to SQLite via `aiosqlite.connect(db_path)`
   - Create table if not exists:
     ```sql
     CREATE TABLE IF NOT EXISTS search_history (
         id INTEGER PRIMARY KEY AUTOINCREMENT,
         timestamp TEXT NOT NULL,
         app TEXT NOT NULL,
         queue_type TEXT NOT NULL,
         item_name TEXT NOT NULL
     );
     CREATE INDEX IF NOT EXISTS idx_search_history_timestamp ON search_history(timestamp DESC);
     ```
   - Use `async with aiosqlite.connect(db_path) as db:` pattern (connection per operation, not long-lived -- aiosqlite is lightweight and SQLite is local)
   - Log: `logger.debug("Search history database initialized at {path}", path=db_path)`

   **`async def insert_search_entry(db_path: Path, app: str, queue_type: str, item_name: str) -> None`**:
   - Connect, insert row with current UTC ISO timestamp (same format as existing: `datetime.now(UTC).isoformat().replace("+00:00", "Z")`)
   - Prune old entries: keep only the most recent 500 rows (DELETE WHERE id NOT IN (SELECT id FROM search_history ORDER BY id DESC LIMIT 500))
   - This keeps the DB bounded without external maintenance

   **`async def get_recent_searches(db_path: Path, limit: int = 50) -> list[dict]`**:
   - Connect, SELECT timestamp, app, queue_type, item_name ORDER BY id DESC LIMIT limit
   - Return list of dicts with keys: name (= item_name), timestamp, app, queue_type
   - Use key "name" (not "item_name") to match the existing search_log dict format that templates expect

   **`async def migrate_from_state(db_path: Path, search_log: list[dict]) -> int`**:
   - If search_log is empty, return 0
   - Insert each entry from search_log into search_history table
   - Map existing dict keys: name -> item_name, timestamp -> timestamp, app -> app, queue_type -> queue_type
   - Return count of migrated entries
   - Log: `logger.info("Migrated {count} search log entries from state.json to SQLite", count=count)`

   All functions use `async with aiosqlite.connect(db_path) as db:` pattern -- open/close per call. This is fine for SQLite because it's local file I/O, not network.

   Import loguru for logging. Use `from __future__ import annotations` per project convention.
  </action>
  <verify>
    <automated>cd /Users/julianamacbook/fetcharr && uv sync --extra dev && uv run python -c "import aiosqlite; print('aiosqlite OK')" && uv run python -c "from fetcharr.db import init_db, insert_search_entry, get_recent_searches, migrate_from_state; print('imports OK')"</automated>
  </verify>
  <done>aiosqlite is in pyproject.toml and installed. fetcharr/db.py exists with init_db, insert_search_entry, get_recent_searches, and migrate_from_state functions. All functions use aiosqlite.connect context manager pattern.</done>
</task>

<task type="auto">
  <name>Task 2: Wire SQLite into engine, scheduler, and web routes</name>
  <files>
    fetcharr/search/engine.py
    fetcharr/search/scheduler.py
    fetcharr/web/routes.py
    fetcharr/state.py
    fetcharr/startup.py
    fetcharr/templates/partials/search_log.html
  </files>
  <action>
1. **fetcharr/search/scheduler.py** -- In `create_lifespan`:
   - Import `from fetcharr.db import init_db, migrate_from_state`
   - After loading state (`load_state`) and before starting scheduler, add:
     ```python
     # Initialize search history database
     db_path = state_path.parent / "fetcharr.db"
     await init_db(db_path)

     # Migrate existing search_log from state.json to SQLite (one-time)
     if state.get("search_log"):
         migrated = await migrate_from_state(db_path, state["search_log"])
         if migrated > 0:
             # Clear search_log from state.json after successful migration
             state["search_log"] = []
             save_state(state, state_path)
     ```
   - Expose `db_path` on `app.state.db_path = db_path`

2. **fetcharr/search/engine.py** -- Replace `append_search_log` with async SQLite insert:
   - Remove the `append_search_log` function entirely (it will no longer be used)
   - Remove the `SEARCH_LOG_MAX = 50` constant
   - Import `from fetcharr.db import insert_search_entry`
   - In `run_radarr_cycle` and `run_sonarr_cycle`, the cycle functions currently call `append_search_log(state, ...)`. But they don't have access to `db_path`. Two options:
     a) Pass db_path as parameter to cycle functions
     b) Import DB_PATH constant

   **Choose option (a)** -- add `db_path: Path` parameter to both `run_radarr_cycle` and `run_sonarr_cycle`, right after `settings`:
   ```python
   async def run_radarr_cycle(
       client: RadarrClient,
       state: FetcharrState,
       settings: Settings,
       db_path: Path,
   ) -> FetcharrState:
   ```

   Replace each `append_search_log(state, "Radarr", "missing", movie["title"])` with:
   ```python
   await insert_search_entry(db_path, "Radarr", "missing", movie["title"])
   ```
   Do the same for all 4 search_log calls (2 in radarr cycle, 2 in sonarr cycle).

   Also add `from pathlib import Path` import if not already present.

3. **fetcharr/search/scheduler.py** -- Update `make_search_job` to pass db_path:
   - The job closure already reads from `app.state`. Update the cycle call to pass `app.state.db_path`:
     ```python
     app.state.fetcharr_state = await cycle_fn(
         client,
         app.state.fetcharr_state,
         app.state.settings,
         app.state.db_path,
     )
     ```

4. **fetcharr/web/routes.py** -- Update routes to read from SQLite:
   - Import `from fetcharr.db import get_recent_searches`
   - In `dashboard` GET handler, replace:
     ```python
     search_log = state.get("search_log", [])
     ```
     with:
     ```python
     search_log = await get_recent_searches(request.app.state.db_path)
     ```
   - In `partial_search_log` GET handler, same replacement:
     ```python
     search_log = await get_recent_searches(request.app.state.db_path)
     ```
   - In `search_now` POST handler, update the cycle function call to pass db_path:
     ```python
     request.app.state.fetcharr_state = await cycle_fn(
         client,
         request.app.state.fetcharr_state,
         request.app.state.settings,
         request.app.state.db_path,
     )
     ```
   - Remove the `search_log` read from state in search_now (it no longer uses state for search log).

5. **fetcharr/state.py** -- Keep `search_log` in `FetcharrState` TypedDict for backwards compatibility (migration reads it), but it will be empty after migration. No structural changes needed, but add a comment noting that search_log is deprecated in favor of SQLite.

6. **fetcharr/templates/partials/search_log.html** -- No changes needed. The template already iterates over a list of dicts with `name`, `timestamp`, `app`, `queue_type` keys, and `get_recent_searches` returns dicts with those same keys.

7. **fetcharr/startup.py** -- No changes needed. Startup doesn't touch search_log.
  </action>
  <verify>
    <automated>cd /Users/julianamacbook/fetcharr && uv run ruff check fetcharr/ --select E,F,I</automated>
    <manual>Verify that no references to append_search_log remain in the codebase (it should be fully removed from engine.py and no longer imported anywhere)</manual>
  </verify>
  <done>append_search_log removed from engine.py. Both cycle functions accept db_path and call insert_search_entry. Scheduler lifespan initializes DB, migrates state.json entries, exposes db_path on app.state. Web routes read search history from SQLite via get_recent_searches. No code references the in-memory search_log for display purposes.</done>
</task>

<task type="auto">
  <name>Task 3: Add tests for SQLite module and update existing tests</name>
  <files>
    tests/test_db.py
    tests/test_search.py
    tests/test_web.py
    tests/conftest.py
  </files>
  <action>
1. Create `tests/test_db.py` with tests for the SQLite module:

   **`test_init_db_creates_table`**: Call `init_db(tmp_path / "test.db")`, then verify the search_history table exists by querying sqlite_master.

   **`test_insert_and_retrieve`**: Insert 3 entries via `insert_search_entry`, retrieve via `get_recent_searches`, verify all 3 returned in reverse chronological order with correct keys (name, timestamp, app, queue_type).

   **`test_get_recent_searches_limit`**: Insert 10 entries, call `get_recent_searches(db_path, limit=3)`, verify only 3 returned.

   **`test_insert_prunes_old_entries`**: Insert 510 entries in a loop, verify table has exactly 500 rows after pruning.

   **`test_migrate_from_state`**: Create a search_log list matching the existing format (list of dicts with name, timestamp, app, queue_type), call `migrate_from_state`, verify entries appear in `get_recent_searches`.

   **`test_migrate_empty_log`**: Call `migrate_from_state` with empty list, verify returns 0.

   **`test_get_recent_searches_empty_db`**: Init db, call `get_recent_searches`, verify returns empty list.

   All tests are async (asyncio_mode=auto in pyproject.toml). Use `tmp_path` fixture for database paths.

2. Update `tests/test_search.py`:
   - Tests for `run_radarr_cycle` and `run_sonarr_cycle` now need a `db_path` parameter. Update existing cycle test calls to pass `tmp_path / "test.db"` as db_path.
   - Before calling cycle functions in tests, call `await init_db(tmp_path / "test.db")` to create the table.
   - Remove any tests for the deleted `append_search_log` function. Replace with a test that verifies cycle functions call `insert_search_entry` (mock it and assert_called).
   - Import `from fetcharr.db import init_db` in test file.

3. Update `tests/test_web.py`:
   - The `test_app` fixture or wherever `app.state` is set up needs to include `app.state.db_path`. Set it to a tmp_path-based path.
   - Call `await init_db(db_path)` in test setup.
   - Update any test that calls `search_now` or checks search log to account for the new db_path parameter on cycle functions.

4. Update `tests/conftest.py` if shared fixtures need db_path:
   - If `_default_state()` is used in conftest, ensure `search_log` is still present (it's kept for backwards compat).
   - Add a `db_path` fixture if multiple test files need it: `@pytest.fixture def db_path(tmp_path): return tmp_path / "test.db"`
  </action>
  <verify>
    <automated>cd /Users/julianamacbook/fetcharr && uv run pytest tests/ -x -q</automated>
  </verify>
  <done>test_db.py has 7+ tests covering init, insert, retrieve, limit, prune, migrate, and empty cases. Existing cycle tests updated with db_path parameter. All tests pass. No ruff violations.</done>
</task>

</tasks>

<verification>
1. `uv run pytest tests/ -x -q` -- all tests pass (existing + new)
2. `uv run ruff check fetcharr/ tests/` -- no lint violations
3. `grep -r "append_search_log" fetcharr/` returns no results (function fully removed)
4. `uv run python -c "from fetcharr.db import init_db, insert_search_entry, get_recent_searches; print('OK')"` -- imports work
</verification>

<success_criteria>
- aiosqlite is in pyproject.toml dependencies
- fetcharr/db.py exists with init_db, insert_search_entry, get_recent_searches, migrate_from_state
- Search history table created with id, timestamp, app, queue_type, item_name columns
- append_search_log completely removed from engine.py
- Both cycle functions accept db_path and write to SQLite
- Scheduler lifespan initializes DB and migrates state.json entries
- Web routes read search history from SQLite
- Pruning keeps DB bounded at 500 entries
- Migration from state.json works and clears the old list
- 7+ new tests in test_db.py, existing tests updated
- All tests pass, no ruff violations
</success_criteria>

<output>
After completion, create `.planning/phases/11-search-enhancements/11-02-SUMMARY.md`
</output>
