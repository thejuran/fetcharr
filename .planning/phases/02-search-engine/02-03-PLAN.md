---
phase: 02-search-engine
plan: 03
type: execute
wave: 3
depends_on: [02-02]
files_modified:
  - fetcharr/search/scheduler.py
  - fetcharr/__main__.py
  - fetcharr/startup.py
  - pyproject.toml
  - tests/test_search.py
autonomous: true
requirements: [SRCH-08]

must_haves:
  truths:
    - "APScheduler runs Radarr and Sonarr search cycles on configurable intervals"
    - "First search cycle runs immediately on startup (next_run_time=now)"
    - "State is saved to disk after each cycle completes (cursors persist across restarts)"
    - "Radarr and Sonarr cycles are independent -- one app failing does not block the other"
    - "Scheduler shuts down cleanly on application exit"
    - "Only enabled apps get scheduler jobs"
    - "Test suite covers search engine utility functions with edge cases"
  artifacts:
    - path: "fetcharr/search/scheduler.py"
      provides: "APScheduler setup with lifespan context manager"
      contains: "AsyncIOScheduler"
    - path: "fetcharr/__main__.py"
      provides: "FastAPI app with lifespan-managed scheduler"
      contains: "uvicorn"
    - path: "pyproject.toml"
      provides: "APScheduler dependency"
      contains: "apscheduler"
    - path: "tests/test_search.py"
      provides: "Search engine test suite"
      contains: "test_"
  key_links:
    - from: "fetcharr/search/scheduler.py"
      to: "fetcharr/search/engine.py"
      via: "Scheduler jobs call run_radarr_cycle and run_sonarr_cycle"
      pattern: "run_radarr_cycle|run_sonarr_cycle"
    - from: "fetcharr/search/scheduler.py"
      to: "fetcharr/state.py"
      via: "Scheduler calls save_state after each cycle"
      pattern: "save_state"
    - from: "fetcharr/__main__.py"
      to: "fetcharr/search/scheduler.py"
      via: "FastAPI lifespan delegates to scheduler's create_lifespan"
      pattern: "lifespan"
---

<objective>
Wire the search engine into a running application with APScheduler driving periodic cycles, FastAPI hosting the lifespan, and state persisted after every cycle. Add the APScheduler dependency and create a comprehensive test suite.

Purpose: This plan turns the search engine from callable functions into an autonomous daemon that runs cycles on a schedule, persists state to survive restarts (SRCH-08), and forms the base for the Phase 3 web UI.

Output: Running Fetcharr application that automatically cycles through wanted items on configurable intervals, with full test coverage of search engine utility functions.
</objective>

<execution_context>
@/Users/julianamacbook/.claude/get-shit-done/workflows/execute-plan.md
@/Users/julianamacbook/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-search-engine/02-CONTEXT.md
@.planning/phases/02-search-engine/02-RESEARCH.md
@.planning/phases/02-search-engine/02-01-SUMMARY.md
@.planning/phases/02-search-engine/02-02-SUMMARY.md
@fetcharr/search/engine.py
@fetcharr/__main__.py
@fetcharr/startup.py
@fetcharr/state.py
@fetcharr/models/config.py
@pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create APScheduler integration with FastAPI lifespan and update entry point</name>
  <files>
    fetcharr/search/scheduler.py
    fetcharr/__main__.py
    fetcharr/startup.py
    pyproject.toml
  </files>
  <action>
    **Add APScheduler dependency (pyproject.toml):**
    Add `"apscheduler>=3.11,<4"` to the `dependencies` list. Use APScheduler 3.x (NOT 4.x which is still alpha).

    **Create fetcharr/search/scheduler.py:**
    This module wires APScheduler to run search cycles on configurable intervals.

    ```python
    from contextlib import asynccontextmanager
    from datetime import datetime, timezone
    from apscheduler.schedulers.asyncio import AsyncIOScheduler
    from fastapi import FastAPI
    from loguru import logger
    from fetcharr.clients.radarr import RadarrClient
    from fetcharr.clients.sonarr import SonarrClient
    from fetcharr.models.config import Settings
    from fetcharr.search.engine import run_radarr_cycle, run_sonarr_cycle
    from fetcharr.state import FetcharrState, load_state, save_state
    ```

    Create a function `create_lifespan(settings: Settings, state_path: Path)` that returns an async context manager for FastAPI's lifespan parameter. The lifespan must:

    1. Load state from disk: `state = load_state(state_path)`
    2. Create long-lived clients for enabled apps (using `async with` or manual open/close):
       - If radarr enabled: `radarr_client = RadarrClient(settings.radarr.url, settings.radarr.api_key.get_secret_value())`
       - If sonarr enabled: `sonarr_client = SonarrClient(settings.sonarr.url, settings.sonarr.api_key.get_secret_value())`
    3. Define wrapper functions for each cycle that:
       - Use `nonlocal state` to access mutable state
       - Call `run_radarr_cycle(client, state, settings)` (or sonarr equivalent)
       - Assign result back to state
       - Call `save_state(state, state_path)` after each cycle
       - Wrap in try/except to catch ALL exceptions -- log error but never crash the scheduler
    4. Create `AsyncIOScheduler()`
    5. Add interval jobs only for enabled apps:
       - Radarr: `scheduler.add_job(radarr_job, "interval", minutes=settings.radarr.search_interval, id="radarr_search", next_run_time=datetime.now(timezone.utc))` -- next_run_time=now for immediate first run per user decision
       - Sonarr: same pattern with sonarr interval
    6. Log job schedule: `"Scheduled {app} search every {interval}m (first run: now)"`
    7. `scheduler.start()`
    8. `yield` (FastAPI serves)
    9. On shutdown: `scheduler.shutdown(wait=False)`, close clients, log "Search engine stopped"

    **State must be shared by reference** -- the wrapper functions capture `state` via nonlocal and `save_state` writes to disk after each mutation. This is safe because APScheduler's AsyncIOScheduler runs jobs on the same event loop (no threading).

    **Update fetcharr/__main__.py:**
    Replace the placeholder implementation with a real FastAPI app:

    1. Import startup, create_lifespan, Settings, STATE_PATH
    2. In `_run()`:
       - Call `settings = await startup(config_path)` (existing startup sequence)
       - Create FastAPI app: `app = FastAPI(lifespan=create_lifespan(settings, state_path))`
       - Run uvicorn: `config = uvicorn.Config(app, host="0.0.0.0", port=8080, log_level="warning")` then `server = uvicorn.Server(config)` then `await server.serve()`
    3. The uvicorn log_level should be "warning" so uvicorn access logs don't clutter the loguru output. Fetcharr's own logging goes through loguru.
    4. Import `from fetcharr.state import STATE_PATH` for the default state path.
    5. Keep KeyboardInterrupt handling in main().

    **Update fetcharr/startup.py:**
    No changes to startup logic, but update the docstring for validate_connections to note that clients are still temporary here -- the scheduler creates its own long-lived clients.
  </action>
  <verify>
    <automated>cd /Users/julianamacbook/fetcharr && python -c "
# Verify APScheduler is importable (dependency added)
from apscheduler.schedulers.asyncio import AsyncIOScheduler
print('APScheduler import OK')

# Verify scheduler module
from fetcharr.search.scheduler import create_lifespan
import inspect
assert callable(create_lifespan)
print('create_lifespan callable OK')

# Verify __main__ updated
import fetcharr.__main__ as m
source = inspect.getsource(m)
assert 'uvicorn' in source or 'FastAPI' in source
print('Entry point updated OK')

print('ALL PASSED')
"</automated>
  </verify>
  <done>APScheduler wired through FastAPI lifespan with configurable intervals per app, immediate first run, state saved after each cycle, independent app jobs, and clean shutdown. Entry point runs uvicorn serving the FastAPI app.</done>
</task>

<task type="auto">
  <name>Task 2: Create search engine test suite</name>
  <files>tests/test_search.py</files>
  <action>
    Create a comprehensive test suite for the search engine utility functions. These are pure function tests (no mocking needed for utils, mocking needed for cycle functions).

    **Test file: tests/test_search.py**

    **Utility function tests (no mocking):**

    1. `test_filter_monitored_keeps_only_monitored` — Items with monitored=True kept, monitored=False and missing key excluded
    2. `test_filter_monitored_empty_list` — Returns empty list for empty input
    3. `test_slice_batch_normal` — Slices correct batch from middle of list, advances cursor
    4. `test_slice_batch_wraps_at_end` — When batch reaches end of list, new cursor wraps to 0
    5. `test_slice_batch_cursor_past_end` — Cursor beyond list length wraps to 0 and slices from start
    6. `test_slice_batch_empty_list` — Returns ([], 0) for empty input
    7. `test_slice_batch_batch_larger_than_remaining` — Batch size larger than remaining items returns what's available, wraps cursor
    8. `test_append_search_log_adds_entry` — Entry has name, timestamp, app, queue_type fields
    9. `test_append_search_log_timestamp_format` — Timestamp ends with "Z" and is valid ISO format
    10. `test_append_search_log_bounded_at_50` — After 55 appends, log has exactly 50 entries (oldest evicted)
    11. `test_deduplicate_to_seasons_removes_duplicates` — Multiple episodes from same season collapse to one entry
    12. `test_deduplicate_to_seasons_preserves_order` — First occurrence wins; output order matches input order
    13. `test_deduplicate_to_seasons_display_name_format` — display_name is "Title - Season N"
    14. `test_deduplicate_to_seasons_missing_series_data` — Falls back to "Series {id}" when series dict missing
    15. `test_filter_sonarr_episodes_excludes_unmonitored` — monitored=False excluded
    16. `test_filter_sonarr_episodes_excludes_future_air_date` — Air date in future excluded
    17. `test_filter_sonarr_episodes_excludes_null_air_date` — airDateUtc=None (TBA) excluded
    18. `test_filter_sonarr_episodes_keeps_past_monitored` — Past air date + monitored=True kept
    19. `test_filter_sonarr_episodes_handles_unparseable_date` — Malformed date string excluded (not crash)

    Use `from fetcharr.state import _default_state` for state fixtures. Use `from datetime import datetime, timezone, timedelta` for date manipulation. No external mocking libraries needed for these tests.

    Each test should be a standalone function (not in a class). Use descriptive assertions. Import all functions from `fetcharr.search.engine`.
  </action>
  <verify>
    <automated>cd /Users/julianamacbook/fetcharr && python -m pytest tests/test_search.py -v --tb=short 2>&1 | tail -30</automated>
  </verify>
  <done>19 tests covering all search engine utility functions with edge cases. All tests pass. Tests cover: filtering (monitored, air dates), batch slicing (normal, wrap, empty, past-end cursor), search log (add, format, eviction), deduplication (collapse, order, display name, fallback), and Sonarr-specific filtering (unmonitored, future, null, past, malformed).</done>
</task>

</tasks>

<verification>
- `python -m pytest tests/ -v` passes (all existing + new tests)
- `python -c "from fetcharr.search.scheduler import create_lifespan"` imports without error
- `python -c "from apscheduler.schedulers.asyncio import AsyncIOScheduler"` imports without error
- APScheduler listed in pyproject.toml dependencies
</verification>

<success_criteria>
- APScheduler 3.x added as dependency and importable
- Scheduler creates interval jobs for enabled apps with configurable intervals
- First cycle runs immediately on startup (next_run_time=now)
- State is saved after each cycle (cursor persistence across restarts = SRCH-08)
- App cycles are independent (one failure doesn't block the other)
- Entry point runs FastAPI with uvicorn and lifespan-managed scheduler
- 19+ new tests covering all utility functions pass
- All existing Phase 1 tests still pass
</success_criteria>

<output>
After completion, create `.planning/phases/02-search-engine/02-03-SUMMARY.md`
</output>
