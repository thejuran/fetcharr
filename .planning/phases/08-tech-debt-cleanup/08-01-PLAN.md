---
phase: 08-tech-debt-cleanup
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - fetcharr/web/routes.py
  - tests/test_web.py
  - fetcharr/templates/settings.html
autonomous: true
requirements: []

must_haves:
  truths:
    - "routes.py does not import load_settings"
    - "test_web.py has no @patch for load_settings and no mock_load parameters"
    - "settings.html form action uses url_for('save_settings') instead of hardcoded /settings"
    - "POST /api/search-now/radarr has a happy-path test returning 200"
    - "test_app fixture includes search_lock for search-now endpoint compatibility"
    - "All 17 SUMMARY.md files have requirements-completed frontmatter"
  artifacts:
    - path: "fetcharr/web/routes.py"
      provides: "Clean imports with no dead load_settings reference"
      contains: "from fetcharr.models.config import Settings as SettingsModel"
    - path: "tests/test_web.py"
      provides: "Cleaned test patches and new search_now happy-path test"
      contains: "test_search_now_happy_path"
    - path: "fetcharr/templates/settings.html"
      provides: "Dynamic url_for form action"
      contains: "url_for('save_settings')"
  key_links:
    - from: "fetcharr/templates/settings.html"
      to: "fetcharr/web/routes.py:save_settings"
      via: "url_for('save_settings') resolving to POST /settings route"
      pattern: "url_for\\('save_settings'\\)"
    - from: "tests/test_web.py:test_search_now_happy_path"
      to: "fetcharr/web/routes.py:search_now"
      via: "TestClient POST to /api/search-now/radarr"
      pattern: "client\\.post.*search-now/radarr"
---

<objective>
Eliminate all remaining tech debt from the v1.0 audit: remove orphaned load_settings import and dead @patch decorators, replace hardcoded form action with url_for, add the missing search_now happy-path test with search_lock fixture, and verify already-fixed audit items.

Purpose: Leave the codebase audit-clean for v1.0 release -- no dead code, no brittle template references, no untested critical paths.
Output: Clean routes.py, cleaned and extended test_web.py, dynamic settings.html form action.
</objective>

<execution_context>
@/Users/julianamacbook/.claude/get-shit-done/workflows/execute-plan.md
@/Users/julianamacbook/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-tech-debt-cleanup/08-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Remove dead load_settings import and @patch decorators</name>
  <files>
    fetcharr/web/routes.py
    tests/test_web.py
  </files>
  <action>
In `fetcharr/web/routes.py`, delete line 22 (`from fetcharr.config import load_settings`). No other code in routes.py references `load_settings` -- this import became orphaned when Phase 6 replaced the reload pattern with direct `SettingsModel(**new_config)` construction.

In `tests/test_web.py`, clean up 3 test functions that have dead `@patch("fetcharr.web.routes.load_settings")` decorators:

1. `test_save_settings_writes_toml` (around line 153):
   - Delete the `@patch("fetcharr.web.routes.load_settings")` decorator line
   - Remove `mock_load` from the function parameters (change `mock_load, client, test_app, tmp_path` to `client, test_app, tmp_path`)
   - Delete the `mock_new_settings = MagicMock()` block and all `mock_new_settings.*` setup lines
   - Delete the `mock_load.return_value = mock_new_settings` line

2. `test_save_settings_preserves_existing_api_key` (around line 197):
   - Same pattern: delete `@patch` decorator, remove `mock_load` param, delete `mock_new_settings` block and `mock_load.return_value` line

3. `test_save_settings_replaces_api_key_when_provided` (around line 238):
   - Same pattern: delete `@patch` decorator, remove `mock_load` param, delete `mock_new_settings` block and `mock_load.return_value` line

CRITICAL: When removing `@patch`, the `mock_load` parameter MUST also be removed from the function signature. If you leave it, `client` will land in the wrong parameter and tests will fail with `AttributeError: 'TestClient' object has no attribute 'post'`.

The tests will continue to pass because they verify TOML output via `config_path.read_text()`, which exercises the actual `save_settings` code path (SettingsModel construction + tomli_w write). The dead patches were providing false confidence that a function was being tested when it was never called.
  </action>
  <verify>
    <automated>cd /Users/julianamacbook/fetcharr && python -m pytest tests/test_web.py -x -q 2>&1 | tail -5</automated>
    <manual>Confirm no import of load_settings in routes.py and no mock_load in test_web.py</manual>
  </verify>
  <done>
    - `grep -n 'load_settings' fetcharr/web/routes.py` returns 0 matches
    - `grep -n 'mock_load' tests/test_web.py` returns 0 matches
    - `grep -n 'mock_new_settings' tests/test_web.py` returns 0 matches
    - All existing test_web.py tests pass
  </done>
</task>

<task type="auto">
  <name>Task 2: Fix settings.html form action and add search_now test</name>
  <files>
    fetcharr/templates/settings.html
    tests/test_web.py
  </files>
  <action>
**Part A: Template url_for fix**

In `fetcharr/templates/settings.html`, line 11, replace the hardcoded form action:
```html
<!-- BEFORE -->
<form method="post" action="/settings" class="space-y-8">

<!-- AFTER -->
<form method="post" action="{{ url_for('save_settings') }}" class="space-y-8">
```

`url_for` is automatically available in Jinja2 templates via FastAPI/Starlette. The route name defaults to the Python function name (`save_settings`), which resolves to `/settings`. The `request` object is already passed to `TemplateResponse` calls (confirmed in routes.py), so this is safe.

**Part B: Add search_lock to test_app fixture**

In `tests/test_web.py`, add `import asyncio` to the imports at the top of the file.

In the `test_app` fixture, after the line `app.state.state_path = tmp_path / "state.json"` (line 90), add:
```python
app.state.search_lock = asyncio.Lock()
```

This makes the fixture complete -- the search_now route accesses `request.app.state.search_lock`, so any test hitting that endpoint would crash without this. Adding it to the fixture is cleaner than per-test setup. This pattern is proven in `tests/test_scheduler.py`.

**Part C: Add search_now happy-path test**

At the end of `tests/test_web.py` (after `test_search_now_invalid_app`), add a new test:

```python
def test_search_now_happy_path(client, test_app):
    """POST /api/search-now/radarr triggers cycle and returns 200 with updated card."""
    with patch(
        "fetcharr.web.routes.run_radarr_cycle",
        new=AsyncMock(return_value=test_app.state.fetcharr_state),
    ), patch(
        "fetcharr.web.routes.save_state",
    ):
        response = client.post("/api/search-now/radarr")
        assert response.status_code == 200
        assert "Radarr" in response.text  # Card partial contains app name
```

The test patches `run_radarr_cycle` to return the existing mock state (so the template can render the app card), and patches `save_state` to prevent actual file I/O. The `search_lock` is already available from the fixture (Part B).
  </action>
  <verify>
    <automated>cd /Users/julianamacbook/fetcharr && python -m pytest tests/test_web.py::test_search_now_happy_path tests/test_web.py::test_save_settings_writes_toml -x -q 2>&1 | tail -5</automated>
    <manual>Confirm settings.html contains url_for and the new test passes</manual>
  </verify>
  <done>
    - `grep 'url_for' fetcharr/templates/settings.html` matches the form action line
    - `grep 'hardcoded.*settings\|action="/settings"' fetcharr/templates/settings.html` returns 0 matches
    - `test_search_now_happy_path` passes
    - `test_app` fixture includes `search_lock`
    - Full test suite passes: `python -m pytest tests/ -x -q`
  </done>
</task>

<task type="auto">
  <name>Task 3: Verify already-fixed audit items and run full test suite</name>
  <files>
    (no files modified -- verification only)
  </files>
  <action>
Verify the 3 audit items that were already fixed before this phase:

1. **REQUIREMENTS.md traceability** -- Confirm no "Planned" entries remain:
   ```bash
   grep -c "Planned" .planning/REQUIREMENTS.md
   # Expected: 0
   ```

2. **ROADMAP.md plan counts** -- Confirm Phase 8 is the only "0/?" entry:
   ```bash
   grep "0/?" .planning/ROADMAP.md
   # Expected: only Phase 8 line (which is expected since we're executing it now)
   ```

3. **SUMMARY.md requirements-completed frontmatter** -- Confirm all 17 plan SUMMARY files have it:
   ```bash
   grep -rl "requirements-completed" .planning/phases/*/0*-SUMMARY.md | wc -l
   # Expected: 17
   ```

Then run the full test suite to confirm zero regressions:
```bash
python -m pytest tests/ -x -q
```

All checks passing = tech debt audit is clean.
  </action>
  <verify>
    <automated>cd /Users/julianamacbook/fetcharr && python -m pytest tests/ -x -q 2>&1 | tail -3</automated>
  </verify>
  <done>
    - All 3 already-fixed audit items verified as resolved
    - Full test suite passes with 0 failures
    - Phase 8 success criteria fully satisfied
  </done>
</task>

</tasks>

<verification>
1. `grep -n 'load_settings' fetcharr/web/routes.py` returns 0 matches
2. `grep -n 'mock_load\|mock_new_settings' tests/test_web.py` returns 0 matches
3. `grep 'url_for.*save_settings' fetcharr/templates/settings.html` returns a match
4. `python -m pytest tests/test_web.py::test_search_now_happy_path -x` passes
5. `python -m pytest tests/ -x -q` -- full suite green, no regressions
6. `grep -rl 'requirements-completed' .planning/phases/*/0*-SUMMARY.md | wc -l` returns 17
</verification>

<success_criteria>
- Dead `load_settings` import removed from routes.py
- Dead `@patch` decorators and `mock_load`/`mock_new_settings` removed from 3 tests in test_web.py
- `settings.html` form action uses `url_for('save_settings')` instead of hardcoded `/settings`
- `POST /api/search-now/radarr` has a happy-path test with search_lock in the fixture
- All 17 SUMMARY.md files confirmed to have `requirements-completed` frontmatter
- Full test suite passes with zero failures
</success_criteria>

<output>
After completion, create `.planning/phases/08-tech-debt-cleanup/08-01-SUMMARY.md`
</output>
